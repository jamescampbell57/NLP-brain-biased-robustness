{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d76b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import BertModel\n",
    "from datasets import load_dataset\n",
    "\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_scheduler\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from datasets import load_metric\n",
    "\n",
    "class PlaceHolderBERT(nn.Module):\n",
    "    def __init__(self, num_out=1, sigmoid=False, return_CLS_representation=False):\n",
    "        super().__init__()\n",
    "        #self.tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')\n",
    "        self.bert = BertModel.from_pretrained('bert-base-cased')\n",
    "        self.linear = nn.Linear(768,num_out)\n",
    "        self.return_CLS_representation = return_CLS_representation\n",
    "        self.sigmoid_bool = sigmoid\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    def forward(self, x):\n",
    "        #embeddings = self.tokenizer(x, return_tensors='pt', padding=True)\n",
    "        #embeddings.to(device)\n",
    "        representations = self.bert(**x).last_hidden_state\n",
    "        cls_representation = representations[:,0,:]\n",
    "        pred = self.linear(cls_representation)\n",
    "        if self.return_CLS_representation:\n",
    "            return cls_representation\n",
    "        if self.sigmoid_bool:\n",
    "            return self.sigmoid(pred)\n",
    "        return pred\n",
    "    \n",
    "    \n",
    "def train(model, dataloader, num_epochs=1): #can scrap keyword\n",
    "    #optimizer as usual\n",
    "    optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "    loss_function = torch.nn.MSELoss()\n",
    "    #learning rate scheduler\n",
    "    num_training_steps = num_epochs * len(dataloader)\n",
    "    lr_scheduler = get_scheduler(name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)\n",
    "\n",
    "    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    #auto logging; progress bar\n",
    "    progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "    #training loop\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch in dataloader: #tryin unpacking text from 'labels' as in model development\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            features = {k: v for k, v in batch.items() if k != 'labels'}\n",
    "            preds = model(features)\n",
    "            loss = loss_function(preds, batch['labels'].float()) #replace .loss\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "            progress_bar.update(1)\n",
    "            \n",
    "\n",
    "def evaluate(model, dataloader):\n",
    "    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    for batch in dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        features = {k: v for k, v in batch.items() if k != 'labels'}\n",
    "        with torch.no_grad():\n",
    "            preds = model(features)\n",
    "            preds = torch.where(preds < .5, 0, 1)\n",
    "            labels = batch['labels'].reshape(preds.shape)\n",
    "            num_correct += (preds==labels).sum()\n",
    "            num_samples += preds.size(0)\n",
    "    return float(num_correct)/float(num_samples)*100 \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "imdb = load_dataset('imdb')\n",
    "sst2 = load_dataset('glue','sst2')\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "#tokenize function\n",
    "def tokenize_imdb(examples):\n",
    "    return tokenizer(examples['text'], padding=\"max_length\", truncation=True)\n",
    "\n",
    "def tokenize_sst2(examples):\n",
    "    return tokenizer(examples['sentence'], padding=\"max_length\", truncation=True)\n",
    "\n",
    "#pre-tokenize entire dataset\n",
    "tokenized_imdb = imdb.map(tokenize_imdb, batched=True)\n",
    "tokenized_sst2 = sst2.map(tokenize_sst2, batched=True)\n",
    "\n",
    "tokenized_imdb = tokenized_imdb.remove_columns([\"text\"])\n",
    "tokenized_imdb = tokenized_imdb.rename_column(\"label\", \"labels\")\n",
    "tokenized_imdb.set_format(\"torch\")\n",
    "\n",
    "tokenized_sst2 = tokenized_sst2.remove_columns([\"sentence\",\"idx\"])\n",
    "tokenized_sst2 = tokenized_sst2.rename_column(\"label\", \"labels\")\n",
    "tokenized_sst2.set_format(\"torch\")\n",
    "\n",
    "\n",
    "### Only for practive\n",
    "imdb_small_train = tokenized_imdb['train'].shuffle(seed=42).select(range(1000))\n",
    "imdb_small_test = tokenized_imdb['test'].shuffle(seed=42).select(range(500))\n",
    "###\n",
    "imdb_train_loader = DataLoader(imdb_small_train, shuffle=True, batch_size=8)\n",
    "imdb_test_loader = DataLoader(imdb_small_test, shuffle=True, batch_size=8)\n",
    "\n",
    "sst2_small_train = tokenized_sst2[\"train\"].shuffle(seed=42).select(range(1000))\n",
    "sst2_small_test = tokenized_sst2[\"validation\"].shuffle(seed=42).select(range(500)) #actual test set is fucked up\n",
    "\n",
    "sst2_train_loader = DataLoader(sst2_small_train, shuffle=True, batch_size=8)\n",
    "sst2_test_loader = DataLoader(sst2_small_test, shuffle=True, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0da8ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import BertModel\n",
    "from datasets import load_dataset\n",
    "\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_scheduler\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ad007e",
   "metadata": {},
   "source": [
    "Dataset available here:\n",
    "https://sheng-z.github.io/ReCoRD-explorer/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdc5e6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "data_path = '/home/ubuntu/NLP-brain-biased-robustness/data/record/'\n",
    "f1 = open(data_path+'train.json') #65709\n",
    "f2 = open(data_path+'dev.json') #7481\n",
    "\n",
    "train_set = json.load(f1)\n",
    "dev_set = json.load(f2)\n",
    "\n",
    "f1.close()\n",
    "f2.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaaa272b",
   "metadata": {},
   "source": [
    "Useful: https://sheng-z.github.io/ReCoRD-explorer/dataset-readme.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25d98a1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def data_split():\n",
    "    CNN = []\n",
    "    Daily_mail = []\n",
    "    for i in range(len(train_set['data'])):\n",
    "        example = train_set['data'][i]\n",
    "        if example['source'] == 'CNN':\n",
    "            CNN.append(example)\n",
    "        if example['source'] == 'Daily mail':\n",
    "            Daily_mail.append(example)\n",
    "    for i in range(len(dev_set['data'])):\n",
    "        example = dev_set['data'][i]\n",
    "        if example['source'] == 'CNN':\n",
    "            CNN.append(example)\n",
    "        if example['source'] == 'Daily mail':\n",
    "            Daily_mail.append(example)\n",
    "    assert len(CNN) + len(Daily_mail) == len(train_set['data']) + len(dev_set['data'])\n",
    "    return CNN, Daily_mail\n",
    "\n",
    "CNN, Daily_mail = data_split()\n",
    "del train_set\n",
    "del dev_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9cb8646",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'f15689cd256daa03fcfd8c357f1376a8a7017b64',\n",
       " 'source': 'CNN',\n",
       " 'passage': {'text': \"Caracas, Venezuela (CNN) -- It's been more than 180 years since Venezuelans saw Simon Bolivar's face. But the revolutionary leader's thick sideburns, bushy eyebrows and steely gaze popped out from behind picture frames Tuesday in new 3-D images unveiled by President Hugo Chavez. Researchers used several software programs to reconstruct the face of the man who liberated Bolivia, Colombia, Ecuador, Panama, Peru and Venezuela from the Spanish crown. Scans of Bolivar's skeletal remains, which investigators exhumed two years ago, factored into their calculations. So did historical paintings, photos of restored uniforms Bolivar wore and images of middle-aged Venezuelans, officials said.\\n@highlight\\nResearchers use computer programs to reconstruct Simon Bolivar's face\\n@highlight\\nVenezuelan President Hugo Chavez unveils new, 3-D portraits of Bolivar\\n@highlight\\nResearchers use data from skeletal remains exhumed two years ago\\n@highlight\\nAn investigation into Bolivar's 1830 death has been inconclusive, the government says\",\n",
       "  'entities': [{'start': 0, 'end': 6},\n",
       "   {'start': 9, 'end': 17},\n",
       "   {'start': 20, 'end': 22},\n",
       "   {'start': 64, 'end': 74},\n",
       "   {'start': 80, 'end': 92},\n",
       "   {'start': 234, 'end': 236},\n",
       "   {'start': 267, 'end': 277},\n",
       "   {'start': 372, 'end': 378},\n",
       "   {'start': 381, 'end': 388},\n",
       "   {'start': 391, 'end': 397},\n",
       "   {'start': 400, 'end': 405},\n",
       "   {'start': 408, 'end': 411},\n",
       "   {'start': 417, 'end': 425},\n",
       "   {'start': 436, 'end': 442},\n",
       "   {'start': 460, 'end': 466},\n",
       "   {'start': 622, 'end': 628},\n",
       "   {'start': 661, 'end': 671},\n",
       "   {'start': 750, 'end': 762},\n",
       "   {'start': 782, 'end': 791},\n",
       "   {'start': 803, 'end': 813},\n",
       "   {'start': 828, 'end': 830},\n",
       "   {'start': 845, 'end': 851},\n",
       "   {'start': 962, 'end': 968}]},\n",
       " 'qas': [{'id': 'f15689cd256daa03fcfd8c357f1376a8a7017b64-8c8714f3e57e83edf542220aaf566d1ee95d5460-43',\n",
       "   'query': 'The broadcast then faded to black, showing @placeholder singing along to the national anthem.',\n",
       "   'answers': [{'start': 267, 'end': 277, 'text': 'Hugo Chavez'},\n",
       "    {'start': 803, 'end': 813, 'text': 'Hugo Chavez'}]},\n",
       "  {'id': 'f15689cd256daa03fcfd8c357f1376a8a7017b64-204e07050cc243261c85b0dcdaaa0d601dc92f13-9',\n",
       "   'query': 'In 1819, @placeholder founded Gran Colombia, a federation of what is now Venezuela, Colombia, Panama and Ecuador.',\n",
       "   'answers': [{'start': 80, 'end': 92, 'text': 'Simon Bolivar'},\n",
       "    {'start': 460, 'end': 466, 'text': 'Bolivar'},\n",
       "    {'start': 622, 'end': 628, 'text': 'Bolivar'},\n",
       "    {'start': 750, 'end': 762, 'text': 'Simon Bolivar'},\n",
       "    {'start': 845, 'end': 851, 'text': 'Bolivar'},\n",
       "    {'start': 962, 'end': 968, 'text': 'Bolivar'}]},\n",
       "  {'id': 'f15689cd256daa03fcfd8c357f1376a8a7017b64-204e07050cc243261c85b0dcdaaa0d601dc92f13-25',\n",
       "   'query': 'In 1819, Bolivar founded @placeholder, a federation of what is now Venezuela, Colombia, Panama and Ecuador.',\n",
       "   'answers': [{'start': 381, 'end': 388, 'text': 'Colombia'}]},\n",
       "  {'id': 'f15689cd256daa03fcfd8c357f1376a8a7017b64-204e07050cc243261c85b0dcdaaa0d601dc92f13-68',\n",
       "   'query': 'In 1819, Bolivar founded Gran Colombia, a federation of what is now @placeholder, Colombia, Panama and Ecuador.',\n",
       "   'answers': [{'start': 9, 'end': 17, 'text': 'Venezuela'},\n",
       "    {'start': 64, 'end': 74, 'text': 'Venezuelans'},\n",
       "    {'start': 417, 'end': 425, 'text': 'Venezuela'},\n",
       "    {'start': 661, 'end': 671, 'text': 'Venezuelans'},\n",
       "    {'start': 782, 'end': 791, 'text': 'Venezuelan'}]},\n",
       "  {'id': 'f15689cd256daa03fcfd8c357f1376a8a7017b64-4e9f23362afc47678210c087cb5d644a9939e098-81',\n",
       "   'query': \"A new $116 million mausoleum to house Bolivar's remains is under construction in @placeholder, Venezuela's government said in a statement Tuesday.\",\n",
       "   'answers': [{'start': 0, 'end': 6, 'text': 'Caracas'}]},\n",
       "  {'id': 'f15689cd256daa03fcfd8c357f1376a8a7017b64-4e9f23362afc47678210c087cb5d644a9939e098-90',\n",
       "   'query': \"A new $116 million mausoleum to house Bolivar's remains is under construction in Caracas, @placeholder's government said in a statement Tuesday.\",\n",
       "   'answers': [{'start': 9, 'end': 17, 'text': 'Venezuela'},\n",
       "    {'start': 64, 'end': 74, 'text': 'Venezuelans'},\n",
       "    {'start': 417, 'end': 425, 'text': 'Venezuela'},\n",
       "    {'start': 661, 'end': 671, 'text': 'Venezuelans'},\n",
       "    {'start': 782, 'end': 791, 'text': 'Venezuelan'}]}]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNN[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9baedfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Official evaluation script for ReCoRD v1.0.\n",
    "(Some functions are adopted from the SQuAD evaluation script.)\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import print_function\n",
    "from collections import Counter\n",
    "import string\n",
    "import re\n",
    "import argparse\n",
    "import json\n",
    "import sys\n",
    "\n",
    "\n",
    "def normalize_answer(s):\n",
    "    \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\n",
    "    def remove_articles(text):\n",
    "        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
    "\n",
    "    def white_space_fix(text):\n",
    "        return ' '.join(text.split())\n",
    "\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return ''.join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "\n",
    "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
    "\n",
    "\n",
    "def f1_score(prediction, ground_truth):\n",
    "    prediction_tokens = normalize_answer(prediction).split()\n",
    "    ground_truth_tokens = normalize_answer(ground_truth).split()\n",
    "    common = Counter(prediction_tokens) & Counter(ground_truth_tokens)\n",
    "    num_same = sum(common.values())\n",
    "    if num_same == 0:\n",
    "        return 0\n",
    "    precision = 1.0 * num_same / len(prediction_tokens)\n",
    "    recall = 1.0 * num_same / len(ground_truth_tokens)\n",
    "    f1 = (2 * precision * recall) / (precision + recall)\n",
    "    return f1\n",
    "\n",
    "\n",
    "def exact_match_score(prediction, ground_truth):\n",
    "    return normalize_answer(prediction) == normalize_answer(ground_truth)\n",
    "\n",
    "\n",
    "def metric_max_over_ground_truths(metric_fn, prediction, ground_truths):\n",
    "    scores_for_ground_truths = []\n",
    "    for ground_truth in ground_truths:\n",
    "        score = metric_fn(prediction, ground_truth)\n",
    "        scores_for_ground_truths.append(score)\n",
    "    return max(scores_for_ground_truths)\n",
    "\n",
    "\n",
    "def evaluate(dataset, predictions):\n",
    "    f1 = exact_match = total = 0\n",
    "    correct_ids = []\n",
    "    for passage in dataset:\n",
    "        for qa in passage['qas']:\n",
    "            total += 1\n",
    "            if qa['id'] not in predictions:\n",
    "                message = 'Unanswered question {} will receive score 0.'.format(qa['id'])\n",
    "                print(message, file=sys.stderr)\n",
    "                continue\n",
    "\n",
    "            ground_truths = list(map(lambda x: x['text'], qa['answers']))\n",
    "            prediction = predictions[qa['id']]\n",
    "\n",
    "            _exact_match = metric_max_over_ground_truths(exact_match_score, prediction, ground_truths)\n",
    "            if int(_exact_match) == 1:\n",
    "                correct_ids.append(qa['id'])\n",
    "            exact_match += _exact_match\n",
    "\n",
    "            f1 += metric_max_over_ground_truths(f1_score, prediction, ground_truths)\n",
    "\n",
    "    exact_match = 100.0 * exact_match / total\n",
    "    f1 = 100.0 * f1 / total\n",
    "    print('* Exact_match: {}\\n* F1: {}'.format(exact_match, f1))\n",
    "\n",
    "    return {'exact_match': exact_match, 'f1': f1}, correct_ids\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    expected_version = '1.0'\n",
    "    parser = argparse.ArgumentParser('Official evaluation script for ReCoRD v1.0.')\n",
    "    parser.add_argument('data_file', help='The dataset file in JSON format.')\n",
    "    parser.add_argument('pred_file', help='The model prediction file in JSON format.')\n",
    "    parser.add_argument('--output_correct_ids', action='store_true',\n",
    "                        help='Output the correctly answered query IDs.')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    with open(args.data_file) as data_file:\n",
    "        dataset_json = json.load(data_file)\n",
    "        if dataset_json['version'] != expected_version:\n",
    "            print('Evaluation expects v-{}, but got dataset with v-{}'.format(\n",
    "                expected_version, dataset_json['version']), file=sys.stderr)\n",
    "        dataset = dataset_json['data']\n",
    "\n",
    "    with open(args.pred_file) as pred_file:\n",
    "        predictions = json.load(pred_file)\n",
    "\n",
    "    metrics, correct_ids = evaluate(dataset, predictions)\n",
    "\n",
    "    if args.output_correct_ids:\n",
    "        print('Output {} correctly answered question IDs.'.format(len(correct_ids)))\n",
    "        with open('correct_ids.json', 'w') as f:\n",
    "            json.dump(correct_ids, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
