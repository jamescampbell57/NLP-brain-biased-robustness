{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9e22934",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import BertModel\n",
    "import datasets\n",
    "from datasets import load_dataset\n",
    "\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_scheduler\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25b1733",
   "metadata": {},
   "source": [
    "We split the data into five categories of clothing (Clothes, Women Clothing, Men Clothing, Baby Clothing, Shoes) and two categories of entertainment products (Music, Movies)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991b7f63",
   "metadata": {},
   "source": [
    "Please pick one among the available configs: ['Wireless_v1_00', 'Watches_v1_00', 'Video_Games_v1_00', 'Video_DVD_v1_00', 'Video_v1_00', 'Toys_v1_00', 'Tools_v1_00', 'Sports_v1_00', 'Software_v1_00', 'Shoes_v1_00', 'Pet_Products_v1_00', 'Personal_Care_Appliances_v1_00', 'PC_v1_00', 'Outdoors_v1_00', 'Office_Products_v1_00', 'Musical_Instruments_v1_00', 'Music_v1_00', 'Mobile_Electronics_v1_00', 'Mobile_Apps_v1_00', 'Major_Appliances_v1_00', 'Luggage_v1_00', 'Lawn_and_Garden_v1_00', 'Kitchen_v1_00', 'Jewelry_v1_00', 'Home_Improvement_v1_00', 'Home_Entertainment_v1_00', 'Home_v1_00', 'Health_Personal_Care_v1_00', 'Grocery_v1_00', 'Gift_Card_v1_00', 'Furniture_v1_00', 'Electronics_v1_00', 'Digital_Video_Games_v1_00', 'Digital_Video_Download_v1_00', 'Digital_Software_v1_00', 'Digital_Music_Purchase_v1_00', 'Digital_Ebook_Purchase_v1_00', 'Camera_v1_00', 'Books_v1_00', 'Beauty_v1_00', 'Baby_v1_00', 'Automotive_v1_00', 'Apparel_v1_00', 'Digital_Ebook_Purchase_v1_01', 'Books_v1_01', 'Books_v1_02']\n",
    "Example of usage:\n",
    "\t`load_dataset('amazon_us_reviews', 'Wireless_v1_00')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d58fa98a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset amazon_us_reviews (/home/ubuntu/.cache/huggingface/datasets/amazon_us_reviews/Baby_v1_00/0.1.0/17b2481be59723469538adeb8fd0a68b0ba363bbbdd71090e72c325ee6c7e563)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60398310926640eca769a66d24b4a3d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset amazon_us_reviews (/home/ubuntu/.cache/huggingface/datasets/amazon_us_reviews/Shoes_v1_00/0.1.0/17b2481be59723469538adeb8fd0a68b0ba363bbbdd71090e72c325ee6c7e563)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67f6f93126e84f02b98ed25a37fb2838",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset amazon_us_reviews (/home/ubuntu/.cache/huggingface/datasets/amazon_us_reviews/Apparel_v1_00/0.1.0/17b2481be59723469538adeb8fd0a68b0ba363bbbdd71090e72c325ee6c7e563)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13690a2d0c9f4264bd8aeeff4f40e708",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset amazon_us_reviews (/home/ubuntu/.cache/huggingface/datasets/amazon_us_reviews/Music_v1_00/0.1.0/17b2481be59723469538adeb8fd0a68b0ba363bbbdd71090e72c325ee6c7e563)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44d59855a5024ef8b229807f479f1ade",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset amazon_us_reviews (/home/ubuntu/.cache/huggingface/datasets/amazon_us_reviews/Video_v1_00/0.1.0/17b2481be59723469538adeb8fd0a68b0ba363bbbdd71090e72c325ee6c7e563)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4df8cfacf02940ad9f899fcd44f367a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#data_path = '/home/ubuntu/NLP-brain-biased-robustness/data/amazon/'\n",
    "#amazon_baby = load_dataset(data_path+'Baby_v1_00/0.1.0/17b2481be59723469538adeb8fd0a68b0ba363bbbdd71090e72c325ee6c7e563/')\n",
    "\n",
    "amazon_baby = load_dataset('amazon_us_reviews','Baby_v1_00')\n",
    "amazon_shoes = load_dataset('amazon_us_reviews','Shoes_v1_00')\n",
    "amazon_clothes = load_dataset('amazon_us_reviews','Apparel_v1_00')\n",
    "amazon_music = load_dataset('amazon_us_reviews','Music_v1_00')\n",
    "amazon_video = load_dataset('amazon_us_reviews','Video_v1_00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb5d2df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /home/ubuntu/.cache/huggingface/datasets/amazon_us_reviews/Baby_v1_00/0.1.0/17b2481be59723469538adeb8fd0a68b0ba363bbbdd71090e72c325ee6c7e563/cache-e4c4210a5c1dbf68.arrow\n",
      "Loading cached shuffled indices for dataset at /home/ubuntu/.cache/huggingface/datasets/amazon_us_reviews/Baby_v1_00/0.1.0/17b2481be59723469538adeb8fd0a68b0ba363bbbdd71090e72c325ee6c7e563/cache-37df28ddebb9f9e2.arrow\n",
      "Loading cached shuffled indices for dataset at /home/ubuntu/.cache/huggingface/datasets/amazon_us_reviews/Shoes_v1_00/0.1.0/17b2481be59723469538adeb8fd0a68b0ba363bbbdd71090e72c325ee6c7e563/cache-7390e0cd92513287.arrow\n",
      "Loading cached shuffled indices for dataset at /home/ubuntu/.cache/huggingface/datasets/amazon_us_reviews/Apparel_v1_00/0.1.0/17b2481be59723469538adeb8fd0a68b0ba363bbbdd71090e72c325ee6c7e563/cache-af87fe3506969fbd.arrow\n",
      "Loading cached shuffled indices for dataset at /home/ubuntu/.cache/huggingface/datasets/amazon_us_reviews/Music_v1_00/0.1.0/17b2481be59723469538adeb8fd0a68b0ba363bbbdd71090e72c325ee6c7e563/cache-5f5ef0035137aff7.arrow\n",
      "Loading cached shuffled indices for dataset at /home/ubuntu/.cache/huggingface/datasets/amazon_us_reviews/Video_v1_00/0.1.0/17b2481be59723469538adeb8fd0a68b0ba363bbbdd71090e72c325ee6c7e563/cache-d55acffbbcf2f765.arrow\n"
     ]
    }
   ],
   "source": [
    "baby_small = amazon_baby['train'].select(range(200000, len(amazon_baby['train']))).shuffle(seed=42).select(range(10000))\n",
    "baby_train = amazon_baby['train'].select(range(200000)).shuffle(seed=42).select(range(50000))\n",
    "shoes_small = amazon_shoes['train'].shuffle(seed=42).select(range(10000))\n",
    "clothes_small = amazon_clothes['train'].shuffle(seed=42).select(range(10000))\n",
    "music_small = amazon_music['train'].shuffle(seed=42).select(range(10000))\n",
    "video_small = amazon_video['train'].shuffle(seed=42).select(range(10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce0319e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(baby_small))\n",
    "print(len(amazon_shoes['train']))\n",
    "print(len(amazon_clothes['train']))\n",
    "print(len(amazon_music['train']))\n",
    "print(len(amazon_video['train']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdff9a19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70b0c87d55f94f5d9511d96aa01785a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "#tokenize function\n",
    "def tokenize_data(examples):\n",
    "    return tokenizer(examples['review_body'], padding=\"max_length\", truncation=True)\n",
    "\n",
    "#pre-tokenize entire dataset\n",
    "tokenized_baby = baby_small.map(tokenize_data, batched=True)\n",
    "#tokenized_shoes = shoes_small.map(tokenize_data, batched=True)\n",
    "#tokenized_clothes = clothes_small.map(tokenize_data, batched=True)\n",
    "#tokenized_music = music_small.map(tokenize_data, batched=True)\n",
    "#tokenized_video = video_small.map(tokenize_data, batched=True)\n",
    "\n",
    "delete_list = ['marketplace', 'customer_id', 'review_id', 'product_id', 'product_parent', 'product_title', 'product_category', 'helpful_votes', 'total_votes', 'vine', 'verified_purchase', 'review_headline', 'review_body', 'review_date']\n",
    "tokenized_baby = tokenized_baby.remove_columns(delete_list)\n",
    "tokenized_baby = tokenized_baby.rename_column(\"star_rating\", \"labels\")\n",
    "tokenized_baby.set_format(\"torch\")\n",
    "\n",
    "#tokenized_shoes = tokenized_shoes.remove_columns(delete_list)\n",
    "#tokenized_shoes = tokenized_shoes.rename_column(\"star_rating\", \"labels\")\n",
    "#tokenized_shoes.set_format(\"torch\")\n",
    "\n",
    "#tokenized_clothes = tokenized_clothes.remove_columns(delete_list)\n",
    "#tokenized_clothes = tokenized_clothes.rename_column(\"star_rating\", \"labels\")\n",
    "#tokenized_clothes.set_format(\"torch\")\n",
    "\n",
    "#tokenized_music = tokenized_music.remove_columns(delete_list)\n",
    "#tokenized_music = tokenized_music.rename_column(\"star_rating\", \"labels\")\n",
    "#tokenized_music.set_format(\"torch\")\n",
    "\n",
    "#tokenized_video = tokenized_video.remove_columns(delete_list)\n",
    "#tokenized_video = tokenized_video.rename_column(\"star_rating\", \"labels\")\n",
    "#tokenized_video.set_format(\"torch\")\n",
    "\n",
    "\n",
    "baby_dataloader = DataLoader(tokenized_baby, shuffle=True, batch_size=8)\n",
    "#shoes_dataloader = DataLoader(tokenized_shoes, shuffle=True, batch_size=8)\n",
    "#clothes_dataloader = DataLoader(tokenized_clothes, shuffle=True, batch_size=8)\n",
    "#music_dataloader = DataLoader(tokenized_music, shuffle=True, batch_size=8)\n",
    "#video_dataloader = DataLoader(tokenized_video, shuffle=True, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60d892cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "import wandb\n",
    "\n",
    "def change_all_keys(pre_odict):\n",
    "    def change_key(odict, old, new):\n",
    "        for _ in range(len(odict)):\n",
    "            k, v = odict.popitem(False)\n",
    "            odict[new if old == k else k] = v\n",
    "            return odict\n",
    "    for key in pre_odict.keys():\n",
    "        if key[:5] == 'bert.':\n",
    "            post_odict = change_key(pre_odict, key, key[5:])\n",
    "            return change_all_keys(post_odict)\n",
    "        if key[:7] == 'linear.':\n",
    "            del pre_odict[key]\n",
    "            return change_all_keys(pre_odict)\n",
    "    return pre_odict\n",
    "\n",
    "class PlaceHolderBERT(nn.Module):\n",
    "    def __init__(self, num_out=5, sigmoid=False, return_CLS_representation=False, brain=True):\n",
    "        super().__init__()\n",
    "        #self.tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')\n",
    "        self.bert = BertModel.from_pretrained('bert-base-cased')\n",
    "        if brain == True:\n",
    "            state_path = '/home/ubuntu/NLP-brain-biased-robustness/state_dicts/fine_tuned_model'\n",
    "            pre_odict = torch.load(state_path)\n",
    "            filtered_odict = change_all_keys(pre_odict)\n",
    "            self.bert.load_state_dict(filtered_odict, strict=True)\n",
    "        self.linear = nn.Linear(768,num_out)\n",
    "        self.return_CLS_representation = return_CLS_representation\n",
    "        self.sigmoid_bool = sigmoid\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    def forward(self, x):\n",
    "        #embeddings = self.tokenizer(x, return_tensors='pt', padding=True)\n",
    "        #embeddings.to(device)\n",
    "        representations = self.bert(**x).last_hidden_state\n",
    "        cls_representation = representations[:,0,:]\n",
    "        pred = self.linear(cls_representation)\n",
    "        if self.return_CLS_representation:\n",
    "            return cls_representation\n",
    "        if self.sigmoid_bool:\n",
    "            return self.sigmoid(pred)\n",
    "        return self.softmax(pred)\n",
    "    \n",
    "    \n",
    "def train(model, dataloader, num_epochs=2): #can scrap keyword\n",
    "    wandb.init(project=\"preliminary results just in case\", entity=\"nlp-brain-biased-robustness\")\n",
    "    wandb.run.name = 'amazon bb bert hp'\n",
    "    wandb.config = {\n",
    "      \"learning_rate\": 5e-5,\n",
    "      \"epochs\": 10,\n",
    "      \"batch_size\": 8\n",
    "    }\n",
    "    #optimizer as usual\n",
    "    optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "    loss_function = torch.nn.MSELoss()\n",
    "    #learning rate scheduler\n",
    "    num_training_steps = num_epochs * len(dataloader)\n",
    "    lr_scheduler = get_scheduler(name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)\n",
    "\n",
    "    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    #auto logging; progress bar\n",
    "    progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "    #training loop\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch in dataloader: #tryin unpacking text from 'labels' as in model development\n",
    "            #batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            features = {k: v.to(device) for k, v in batch.items() if k != 'labels'}\n",
    "            preds = model(features)\n",
    "            targets = F.one_hot((batch['labels']-1).to(torch.int64), num_classes=5).to(device)\n",
    "            loss = loss_function(preds, targets.float()) #replace .loss\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "            progress_bar.update(1)\n",
    "        baby_score = evaluate(model, baby_dataloader)\n",
    "        print(baby_score)\n",
    "        wandb.log({\"baby\": baby_score})\n",
    "        shoes_score = evaluate(model, shoes_dataloader)\n",
    "        print(shoes_score)\n",
    "        wandb.log({\"shoes\": shoes_score})\n",
    "        clothes_score = evaluate(model, clothes_dataloader)\n",
    "        print(clothes_score)\n",
    "        wandb.log({\"clothes\": clothes_score})\n",
    "        music_score = evaluate(model, music_dataloader)\n",
    "        print(music_score)\n",
    "        wandb.log({\"music\": music_score})\n",
    "        video_score = evaluate(model, video_dataloader)\n",
    "        print(video_score)\n",
    "        wandb.log({\"video\": video_score})\n",
    "        print(\"_________________________________________________\")\n",
    "            \n",
    "\n",
    "def evaluate(model, dataloader):\n",
    "    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    for batch in dataloader:\n",
    "        #batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        features = {k: v.to(device) for k, v in batch.items() if k != 'labels'}\n",
    "        with torch.no_grad():\n",
    "            preds = model(features)\n",
    "            preds = torch.argmax(preds, axis=1)\n",
    "            labels = F.one_hot((batch['labels']-1).to(torch.int64), num_classes=5).to(device)\n",
    "            labels = torch.argmax(labels, axis=1)\n",
    "            num_correct += (preds==labels).sum()\n",
    "            num_samples += preds.size(0)\n",
    "    return float(num_correct)/float(num_samples)*100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cf17a3b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = PlaceHolderBERT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcb26d5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1747, 0.2500, 0.1621, 0.1889, 0.2243],\n",
       "        [0.1744, 0.2495, 0.1623, 0.1892, 0.2247],\n",
       "        [0.1734, 0.2429, 0.1614, 0.1958, 0.2264],\n",
       "        [0.1739, 0.2409, 0.1613, 0.1990, 0.2248],\n",
       "        [0.1739, 0.2490, 0.1621, 0.1902, 0.2249],\n",
       "        [0.1744, 0.2472, 0.1619, 0.1914, 0.2250],\n",
       "        [0.1746, 0.2475, 0.1615, 0.1918, 0.2246],\n",
       "        [0.1743, 0.2472, 0.1614, 0.1917, 0.2253]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = next(iter(baby_dataloader))\n",
    "features = {k: v for k, v in example.items() if k != 'labels'}\n",
    "output = model(features)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9144c53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
       "       grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(output, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04225967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1742, 0.2468, 0.1615, 0.1925, 0.2250],\n",
      "        [0.1743, 0.2491, 0.1622, 0.1896, 0.2248],\n",
      "        [0.1744, 0.2475, 0.1614, 0.1921, 0.2246],\n",
      "        [0.1741, 0.2490, 0.1613, 0.1908, 0.2247],\n",
      "        [0.1748, 0.2502, 0.1618, 0.1889, 0.2242],\n",
      "        [0.1745, 0.2497, 0.1617, 0.1895, 0.2247],\n",
      "        [0.1748, 0.2498, 0.1620, 0.1891, 0.2243],\n",
      "        [0.1745, 0.2496, 0.1620, 0.1892, 0.2248]], device='cuda:0')\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "tensor([[0, 0, 0, 0, 1],\n",
      "        [0, 0, 0, 0, 1],\n",
      "        [0, 0, 0, 0, 1],\n",
      "        [0, 0, 1, 0, 0],\n",
      "        [0, 0, 0, 0, 1],\n",
      "        [0, 0, 0, 0, 1],\n",
      "        [0, 0, 0, 0, 1],\n",
      "        [0, 0, 0, 0, 1]], device='cuda:0')\n",
      "tensor([4, 4, 4, 2, 4, 4, 4, 4], device='cuda:0')\n",
      "8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "num_correct = 0\n",
    "num_samples = 0\n",
    "batch = next(iter(baby_dataloader))\n",
    "    #batch = {k: v.to(device) for k, v in batch.items()}\n",
    "features = {k: v.to(device) for k, v in batch.items() if k != 'labels'}\n",
    "with torch.no_grad():\n",
    "    preds = model(features)\n",
    "    print(preds)\n",
    "    preds = torch.argmax(preds, axis=1)\n",
    "    print(preds)\n",
    "    labels = F.one_hot((batch['labels']-1).to(torch.int64), num_classes=5).to(device)\n",
    "    print(labels)\n",
    "    labels = torch.argmax(labels, axis=1)\n",
    "    print(labels)\n",
    "    num_correct += (preds==labels).sum()\n",
    "    num_samples += preds.size(0)\n",
    "    print(num_samples)\n",
    "float(num_correct)/float(num_samples)*100 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
