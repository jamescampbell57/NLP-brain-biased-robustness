{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d33d79ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import BertModel\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f6c730",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "\n",
    "harry_potter = loadmat('data/brain_data/subject_1.mat')\n",
    "\n",
    "\n",
    "words = []\n",
    "for i in range(5176):\n",
    "    word = harry_potter['words'][0][i][0][0][0][0]\n",
    "    words.append(word)\n",
    "\n",
    "word_times = []\n",
    "for i in range(5176):\n",
    "    word_time = harry_potter['words'][0][i][1][0][0]\n",
    "    word_times.append(word_time)\n",
    "\n",
    "tr_times = []\n",
    "for i in range(1351):\n",
    "    tr_time = harry_potter['time'][i,0]\n",
    "    tr_times.append(tr_time)\n",
    "\n",
    "dont_include_indices = [i for i in range(15)] + [i for i in range(335,355)] + [i for i in range(687,707)] + [i for i in range(966,986)] + [i for i in range(1346,1351)]\n",
    "\n",
    "X_fmri = harry_potter['data']\n",
    "\n",
    "useful_X_fmri = np.delete(X_fmri, dont_include_indices,axis=0)\n",
    "\n",
    "tr_times_arr = np.asarray(tr_times)\n",
    "\n",
    "useful_tr_times = np.delete(tr_times_arr, dont_include_indices)\n",
    "\n",
    "sentences = [[]]*1271\n",
    "for idx, useful_tr_time in enumerate(useful_tr_times):\n",
    "    sentence= []\n",
    "    for word, word_time in zip(words,word_times):\n",
    "        if useful_tr_time - 10 <= word_time <= useful_tr_time:\n",
    "            sentence.append(word)\n",
    "    sentences[idx] = sentence   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bccc09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_sentences = ['']*1271\n",
    "for idx, sentence in enumerate(sentences):\n",
    "    for word in sentence:\n",
    "        actual_sentences[idx] = actual_sentences[idx] + word + ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a48332e",
   "metadata": {},
   "outputs": [],
   "source": [
    "useful_X_fmri.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59243be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BrainBiasedBERT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')\n",
    "        self.bert = BertModel.from_pretrained('bert-base-cased')\n",
    "        self.linear = nn.Linear(768,37913)\n",
    "    def forward(self, x):\n",
    "        embeddings = self.tokenizer(x, return_tensors='pt', padding=True)\n",
    "        representations = self.bert(**embeddings).last_hidden_state\n",
    "        cls_representation = representations[:,0,:]\n",
    "        pred_fmri = self.linear(cls_representation)\n",
    "        return pred_fmri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc1adad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BrainBiasedBERT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3171c7f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pred_fmri = model(actual_sentences[:5])\n",
    "pred_fmri.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf089c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fmri = torch.as_tensor(useful_X_fmri)\n",
    "truth_fmri = fmri[:5,:]\n",
    "truth_fmri.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f7e6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60c5dc4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss_function(pred_fmri, truth_fmri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853dcdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataset = []\n",
    "for i in range(1271):\n",
    "    dataset.append((actual_sentences[i], fmri[i,:]))\n",
    "    \n",
    "#TRAIN TEST SPLIT HAS OVERLAP IN WORDS AND IN BRAIN STATE\n",
    "n_rows = len(dataset)\n",
    "train_dataset = dataset[:int(.8*n_rows)]\n",
    "val_dataset = dataset[int(.8*n_rows):]\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=False)\n",
    "test_dataloader = DataLoader(val_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1277f480",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "full_num_epochs = 15\n",
    "loss_over_time = []\n",
    "time = []\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-4)\n",
    "for epoch in range(full_num_epochs):\n",
    "    epoch += 1\n",
    "    for batch_idx, (data, targets) in enumerate(train_dataloader):\n",
    "        #print(data[0])\n",
    "        #print(targets)\n",
    "        preds = model(data[0])\n",
    "        loss = loss_function(preds, targets.float())\n",
    "        loss_over_time.append(loss.item())\n",
    "        time.append(batch_idx*epoch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    plt.plot(time, loss_over_time)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8960a8a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#model.eval()\n",
    "#with torch.no_grad():\n",
    "#    test_losses = []\n",
    "#    for x, y in test_dataloader:\n",
    "#        preds = model(x[0])\n",
    "#        test_loss = loss_function(preds,y.float())\n",
    "#        test_losses.append(test_loss)\n",
    "        \n",
    "#print(torch.mean(torch.as_tensor(test_losses))) \n",
    "#model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddf9b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'state_dict')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367c06a8",
   "metadata": {},
   "source": [
    "# Loading evaluation suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a120a2b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mnli = load_dataset('multi_nli')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4d0e06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
