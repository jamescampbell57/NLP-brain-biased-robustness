{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d33d79ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import BertModel\n",
    "from tqdm.notebook import tnrange, tqdm_notebook\n",
    "#from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87f6c730",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "\n",
    "harry_potter = loadmat('data/brain_data/subject_1.mat')\n",
    "\n",
    "words = []\n",
    "for i in range(5176):\n",
    "    word = harry_potter['words'][0][i][0][0][0][0]\n",
    "    words.append(word)\n",
    "\n",
    "word_times = []\n",
    "for i in range(5176):\n",
    "    word_time = harry_potter['words'][0][i][1][0][0]\n",
    "    word_times.append(word_time)\n",
    "\n",
    "tr_times = []\n",
    "for i in range(1351):\n",
    "    tr_time = harry_potter['time'][i,0]\n",
    "    tr_times.append(tr_time)\n",
    "\n",
    "dont_include_indices = [i for i in range(15)] + [i for i in range(335,355)] + [i for i in range(687,707)] + [i for i in range(966,986)] + [i for i in range(1346,1351)]\n",
    "\n",
    "X_fmri = harry_potter['data']\n",
    "\n",
    "useful_X_fmri = np.delete(X_fmri, dont_include_indices,axis=0)\n",
    "\n",
    "tr_times_arr = np.asarray(tr_times)\n",
    "\n",
    "useful_tr_times = np.delete(tr_times_arr, dont_include_indices)\n",
    "\n",
    "sentences = [[]]*1271\n",
    "for idx, useful_tr_time in enumerate(useful_tr_times):\n",
    "    sentence= []\n",
    "    for word, word_time in zip(words,word_times):\n",
    "        if useful_tr_time - 10 <= word_time <= useful_tr_time:\n",
    "            sentence.append(word)\n",
    "    sentences[idx] = sentence   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bccc09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_sentences = [''] * 1271\n",
    "for idx, sentence in enumerate(sentences):\n",
    "    for word in sentence:\n",
    "        actual_sentences[idx] = actual_sentences[idx] + word + ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a48332e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1271, 37913)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "useful_X_fmri.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b59243be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BrainBiasedBERT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')\n",
    "        self.bert = BertModel.from_pretrained('bert-base-cased')\n",
    "        self.linear = nn.Linear(768,37913)\n",
    "    def forward(self, x):\n",
    "        embeddings = self.tokenizer(x, return_tensors='pt', padding=True)\n",
    "        representations = self.bert(**embeddings).last_hidden_state\n",
    "        cls_representation = representations[:,0,:]\n",
    "        pred_fmri = self.linear(cls_representation)\n",
    "        return pred_fmri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efc1adad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = BrainBiasedBERT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3171c7f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 37913])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_fmri = model(actual_sentences[:5])\n",
    "pred_fmri.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecf089c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 37913])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fmri = torch.as_tensor(useful_X_fmri)\n",
    "truth_fmri = fmri[:5,:]\n",
    "truth_fmri.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67f7e6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b60c5dc4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(313277.2812, grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_function(pred_fmri, truth_fmri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "853dcdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataset = []\n",
    "for i in range(1271):\n",
    "    dataset.append((actual_sentences[i], fmri[i,:]))\n",
    "    \n",
    "#TRAIN TEST SPLIT HAS OVERLAP IN WORDS AND IN BRAIN STATE\n",
    "n_rows = len(dataset)\n",
    "train_dataset = dataset[:int(.8*n_rows)]\n",
    "val_dataset = dataset[int(.8*n_rows):]\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=False)\n",
    "test_dataloader = DataLoader(val_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1277f480",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dddf0b28cc34345ba066830d37d8e4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch Loop:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6df0fbf964ae4956a05e1e3f72e12da4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Loop:   0%|          | 0/1016 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     16\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 17\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     batch_idx \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     19\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(time, loss_over_time)\n",
      "File \u001b[0;32m~/anaconda3/envs/brain/lib/python3.9/site-packages/torch/optim/optimizer.py:88\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/brain/lib/python3.9/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/brain/lib/python3.9/site-packages/torch/optim/adam.py:141\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[38;5;66;03m# record the step after step update\u001b[39;00m\n\u001b[1;32m    139\u001b[0m             state_steps\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m--> 141\u001b[0m     \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m           \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m           \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m           \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m           \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m           \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m           \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m           \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m           \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m           \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m           \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m           \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m           \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/anaconda3/envs/brain/lib/python3.9/site-packages/torch/optim/_functional.py:97\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m     94\u001b[0m     grad \u001b[38;5;241m=\u001b[39m grad\u001b[38;5;241m.\u001b[39madd(param, alpha\u001b[38;5;241m=\u001b[39mweight_decay)\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[0;32m---> 97\u001b[0m \u001b[43mexp_avg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m exp_avg_sq\u001b[38;5;241m.\u001b[39mmul_(beta2)\u001b[38;5;241m.\u001b[39maddcmul_(grad, grad\u001b[38;5;241m.\u001b[39mconj(), value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta2)\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m amsgrad:\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;66;03m# Maintains the maximum of all 2nd moment running avg. till now\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "full_num_epochs = 15\n",
    "loss_over_time = []\n",
    "time = []\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-4)\n",
    "for epoch in tnrange(full_num_epochs, desc=\"Epoch Loop\"):\n",
    "    epoch += 1\n",
    "    batch_idx = 0\n",
    "    for (data, targets) in tqdm_notebook(train_dataloader, desc=\"Training Loop\"):\n",
    "        preds = model(data[0])\n",
    "        loss = loss_function(preds, targets.float())\n",
    "        loss_over_time.append(loss.item())\n",
    "        time.append(batch_idx*epoch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        batch_idx += 1\n",
    "    plt.plot(time, loss_over_time)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8960a8a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#model.eval()\n",
    "#with torch.no_grad():\n",
    "#    test_losses = []\n",
    "#    for x, y in test_dataloader:\n",
    "#        preds = model(x[0])\n",
    "#        test_loss = loss_function(preds,y.float())\n",
    "#        test_losses.append(test_loss)\n",
    "        \n",
    "#print(torch.mean(torch.as_tensor(test_losses))) \n",
    "#model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddf9b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'state_dict')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367c06a8",
   "metadata": {},
   "source": [
    "# Loading evaluation suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a120a2b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#mnli = load_dataset('multi_nli')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4d0e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnli['validation_matched']['gold_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f7b526",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# telephone - face2face/letter\n",
    "header = ['index'] + list(train.columns)\n",
    "\n",
    "def write_split(s, tag, genre):\n",
    "    cnt = 0\n",
    "    with open(\"{}.tsv\".format(tag), 'w', encoding=\"UTF-8\") as fout:\n",
    "        writer = csv.writer(fout, delimiter='\\t')\n",
    "        writer.writerow(header)\n",
    "        for i in s.itertuples():\n",
    "            if i[3] == genre:\n",
    "                cnt += 1\n",
    "                writer.writerow(list(i))\n",
    "    print(genre, cnt)\n",
    "\n",
    "write_split(train, \"train-telephone\", \"telephone\")\n",
    "write_split(dev, \"dev-telephone\", \"telephone\")\n",
    "write_split(dev, \"dev-letters\", \"letters\")\n",
    "write_split(dev, \"dev-facetoface\", \"facetoface\")\n",
    "© 2022 GitHub, Inc.\n",
    "Terms\n",
    "Privacy\n",
    "Security\n",
    "Status\n",
    "Docs\n",
    "Contact "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brain",
   "language": "python",
   "name": "brain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
